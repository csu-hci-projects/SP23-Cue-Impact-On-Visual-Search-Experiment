# SP23-Cue-Impact-On-Visual-Search-Experiment

## Introduction: 
We created a Unity project with the intent to determine if visual and or audio aids could help a search in a 2D virtual enviroment, and investigating the impact they can have on UI navigation. There are five scenes within the project being Menu, NoAid, AudioAid, VisualAid, and BothAid. 

## Video Overview:
Here is a (WILL GO HERE)[link] to a video walking through and explaining the code wrote to make this project come to life. 

### Menu: 
Upon opening the application you are brought to the menu, a simple interface where you can select each of the 4 search tasks and exit the application. 

### NoAid: 
This is the first example of a Search Task, users enter a scene where they have a 2x7 grid of the image they have to find in front of them. After clicking one time, a timer starts and the 2x7 grid is randomized with 21 different shapes and objects. In the top right corner is a counter and an image of the object they are designed to find. They will click on the selected image ten times and their time is recorded. 

### AudioAid: 
This is the exact same as NoAid, another search task with the same constraints. However, depending on where the target object is randomized to on the grid audio will play. If the image is on the right half of the grid audio will play out of the right ear, similarly for the left and if the target object is in the middle, both ears will play sound. 

### VisualAid: 
This is the exact same as NoAid, another search task with the same constraints. However, a subtle, transparent orange outline surrounds the target object assumingly aiding the search.

### BothAid: 
Again, the same search task but this time both aids are used in conjunction with one another. Sound plays depending on where the target shape is randomized to and an orange outline surrounds the shape aswell.

#### Assets:
All shapes and iconography were created by Ayden Adair and Rudolph Zupetz in Photoshop and or other similar applications.
